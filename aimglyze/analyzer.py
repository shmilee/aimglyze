# -*- coding: utf-8 -*-

# Copyright (c) 2025 shmilee

import os
import openai
import base64
import json_repair
import yaml
import functools
print = functools.partial(print, flush=True)


class Analyzer(object):
    '''
    è¯†åˆ«å›¾ä¸­å†…å®¹ï¼Œè¿”å› JSON è¾“å‡º
    '''
    default_model = "NO-MODEL"

    def __init__(self, model=None, max_tokens=8192,
                 temperature=1.0, thinking=False,
                 system_prompt=None, user_prompt=None, **kwargs):
        self.set_AiClient()
        self.model = model or self.default_model
        self.max_tokens = max_tokens
        self.temperature = temperature
        self.thinking = thinking
        self.system_prompt = system_prompt or """
            ç”¨æˆ·å°†æä¾›ä¸€äº›å›¾ç‰‡ï¼Œä½ ä½œä¸ºä¸€ä¸ªä¸“ä¸šçš„å›¾ç‰‡åˆ†æå™¨ï¼Œ
            ä»»åŠ¡æ˜¯å‡†ç¡®åˆ†æå›¾ç‰‡å†…å®¹ï¼Œç¡®å®šé€‚åˆå›¾ç‰‡çš„ä¸€äº›æ ‡ç­¾ï¼Œ
            å¹¶æ ¹æ®ç”¨æˆ·è¦æ±‚æè¿°å›¾ç‰‡ã€‚
            è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼š
            {
                "name": "å›¾ç‰‡çš„åç§°",
                "desc": "å›¾ç‰‡çš„è¯¦ç»†æè¿°",
                "tags": ["ä¸€äº›é€‚åˆå›¾ç‰‡çš„æ ‡ç­¾"]
            }
        """
        self.user_prompt = user_prompt or 'å›¾ç‰‡æè¿°æ§åˆ¶åœ¨200å­—å·¦å³ã€‚'

    def set_AiClient(self):
        # for self.client.chat.completions.create
        raise NotImplementedError()

    def _create_img_msg(self, image_data: bytes, mime_type: str):
        base64_data = base64.b64encode(image_data).decode('utf-8')
        return {
            "type": "image_url",
            "image_url": {
                "url": f"data:{mime_type};base64,{base64_data}"
            }
        }

    def _create_thinking_kwargs(self):
        return dict(extra_body={
            "thinking": {
                "type": "enabled" if self.thinking else "disabled",
            }
        })

    def create_response(self, image_data: bytes, mime_type: str):
        img_msg = self._create_img_msg(image_data, mime_type)
        text_msg = {"type": "text", "text": self.user_prompt}
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": [img_msg, text_msg]},
            ],
            response_format={
                "type": "json_object",
            },
            max_tokens=self.max_tokens,
            temperature=self.temperature,
            stream=True,  # å¯ç”¨æµå¼è¾“å‡º
            **self._create_thinking_kwargs()
        )
        return response

    def get_response_message(self, response):
        # åˆå§‹åŒ–å˜é‡ç”¨äºæ”¶é›†æµå¼æ•°æ®
        reasoning_content = ""     # æ¨ç†è¿‡ç¨‹å†…å®¹
        content = ""               # å›ç­”å†…å®¹
        reasoning_started = False  # æ¨ç†è¿‡ç¨‹å¼€å§‹æ ‡å¿—
        content_started = False    # å†…å®¹è¾“å‡ºå¼€å§‹æ ‡å¿—
        for idx, chunk in enumerate(response, 1):
            if not chunk.choices:
                continue
            delta = chunk.choices[0].delta
            # å¤„ç†æµå¼æ¨ç†è¿‡ç¨‹è¾“å‡º
            if (self.thinking and hasattr(delta, 'reasoning_content')
                    and delta.reasoning_content):
                if not reasoning_started:
                    print("\nğŸ§  æ€è€ƒè¿‡ç¨‹ï¼š")
                    reasoning_started = True
                reasoning_content += delta.reasoning_content
                if reasoning_content.strip():
                    print(delta.reasoning_content, end="")
            # å¤„ç†æµå¼å›ç­”å†…å®¹è¾“å‡º
            if hasattr(delta, 'content') and delta.content:
                if not content_started:
                    print("\nğŸ’¬ å›ç­”å†…å®¹ï¼š")
                    content_started = True
                content += delta.content
                if content.strip():
                    print(delta.content, end="")
        return content.strip()

    def chat(self, image_data: bytes, mime_type: str):
        print('ğŸ¤– Creating chat ...', end=' ')
        response = self.create_response(image_data, mime_type)
        print('Done.')
        msg = self.get_response_message(response)
        # ref: https://github.com/mangiucugna/json_repair
        obj = json_repair.repair_json(msg, return_objects=True,
                                      ensure_ascii=False)
        # with open('./sample-msg.json', 'w') as fp:
        #    import json
        #    json.dump(obj, fp, indent=2, ensure_ascii=False)
        return obj


class GeminiAnalyzer(Analyzer):
    '''
    é€‰ç”¨å…¼å®¹ openai æ¥å£
    '''
    default_model = "gemini-2.5-flash"

    def set_AiClient(self):
        # https://ai.google.dev/gemini-api/docs/openai?hl=zh-cn
        # need GEMINI_API_KEY environment variable
        self.client = openai.OpenAI(
            api_key=os.environ.get("GEMINI_API_KEY"),
            base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
        )

    def _create_thinking_kwargs(self):
        return dict(extra_body={
            'extra_body': {
                "google": {
                    "thinking_config": {
                        "thinking_budget": "low",
                        "include_thoughts": True
                    }
                }
            }
        }) if self.thinking else dict(reasoning_effort="none")


class GenaiAnalyzer(Analyzer):
    '''
    #from google import genai ä¸å…¼å®¹ OpenAI
    https://ai.google.dev/gemini-api/docs/image-understanding?hl=zh-cn
    '''
    default_model = "gemini-2.5-flash"

    def set_AiClient(self):
        # need GEMINI_API_KEY environment variable
        from google import genai
        self.client = genai.Client()

    def create_response(self, image_data: bytes, mime_type: str):
        from google.genai import types
        response = self.client.models.generate_content_stream(  # æµå¼å“åº”
            model=self.model,
            config=types.GenerateContentConfig(
                system_instruction=self.system_prompt,
                # TODO https://ai.google.dev/gemini-api/docs/structured-output?hl=zh-cn
                response_mime_type="application/json",
                # https://ai.google.dev/gemini-api/docs/thinking?hl=zh-cn
                thinking_config=(
                    types.ThinkingConfig(thinking_level="low")
                    if self.thinking else types.ThinkingConfig(thinking_budget=0))
            ),
            contents=[
                types.Part.from_bytes(data=image_data, mime_type=mime_type),
                self.user_prompt
            ],
            # TODO
            # max_tokens=self.max_tokens,
            # temperature=self.temperature,
        )
        return response


class ZhipuAnalyzer(Analyzer):
    # https://bigmodel.cn/usercenter/proj-mgmt/apikeys
    # https://docs.bigmodel.cn/cn/guide/models/free/glm-4.6v-flash
    default_model = "glm-4.6v-flash"

    def set_AiClient(self):
        # need ZAI_API_KEY environment variable
        from zai import ZhipuAiClient
        self.client = ZhipuAiClient(
            api_key=os.environ.get("ZAI_API_KEY")
        )

    def _create_thinking_kwargs(self):
        return dict(thinking={
            "type": "enabled" if self.thinking else "disabled",
        })


class DeepseekAnalyzer(Analyzer):
    '''
    ç¦ç”¨æ·±åº¦æ€è€ƒæ¨¡å¼å¯åŠ é€Ÿå“åº”, å‡å°‘è´¹ç”¨ã€‚
    å¯ç”¨æ€è€ƒæ¨¡å¼ temperature å‚æ•°å¤±æ•ˆã€‚
    https://api-docs.deepseek.com/zh-cn/guides/thinking_mode
    '''
    default_model = "deepseek-chat"

    def set_AiClient(self):
        # https://api-docs.deepseek.com/zh-cn/
        # need XXX_API_KEY environment variable
        self.client = openai.OpenAI(
            api_key=os.environ.get('DEEPSEEK_API_KEY'),
            base_url="https://api.deepseek.com")


# TODO å…¶ä»–å…è´¹å¹³å° https://github.com/fruitbars/simple-one-api
AnalyzerMap = dict(
    default=ZhipuAnalyzer,
    GeminiAnalyzer=GeminiAnalyzer,
    GenaiAnalyzer=GenaiAnalyzer,
    ZhipuAnalyzer=ZhipuAnalyzer,
    DeepseekAnalyzer=DeepseekAnalyzer,  # ä¸å…è´¹
)


def get_analyzer_config(yaml_config: str):
    '''
    ```yaml
    analyzer: class-name
    setting:
       model: deepseek-chat
       system_prompt: XXX
       other-init-kwargs: XXX...
    ```
    '''
    if os.path.isfile(yaml_config):
        with open(yaml_config, 'r', encoding='utf-8') as yc:
            config = yaml.safe_load(yc)
        return dict(
            analyzer=config.get('analyzer', None) or 'default',
            setting=config.get('setting', None) or {}
        )
    else:
        raise FileNotFoundError(f'File {yaml_config} not found!')


if __name__ == "__main__":
    # å•å¼ å›¾ç‰‡åˆ†æ
    config = get_analyzer_config('./App-DescTags/config.yaml')
    analyzer = AnalyzerMap[config['analyzer']](**config['setting'])
    image_path = "./logos/aimglyze-light.png"  # æµ‹è¯• logo å›¾ç‰‡
    with open(image_path, "rb") as image_file:
        image_data = image_file.read()
    ext = os.path.splitext(image_path)[1].lower()
    mime_type = f"image/{ext[1:] if ext else 'png'}"
    msg = analyzer.chat(image_data, mime_type)
    print(f"\nğŸ¤– åˆ†æç»“æœ:\n{msg}")
