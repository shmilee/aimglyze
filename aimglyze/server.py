#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright (c) 2025 shmilee

import os
import sys
import json
import locale
import yaml
import base64
import mimetypes
import hashlib
import time
import shutil
from pathlib import Path
from http.server import HTTPServer, BaseHTTPRequestHandler
from urllib.parse import urlparse, parse_qs
from io import BytesIO
import threading
# å¯¼å…¥ç°æœ‰çš„åˆ†æå™¨æ¨¡å—
from .analyzer import get_analyzer_config, AnalyzerMap
import functools
print = functools.partial(print, flush=True)


class AnalysisServer(object):
    """åˆ†ææœåŠ¡å™¨"""

    def __init__(self, config_path):
        if config_path is None or not os.path.exists(config_path):
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")
        self.config_path = os.path.abspath(config_path)
        self.config_dir = os.path.dirname(self.config_path)
        print(f"é…ç½®æ–‡ä»¶: {self.config_path}")
        # ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–æˆ–é»˜è®¤
        self.config = self.load_config(self.config_path)

        # åˆå§‹åŒ–åˆ†æå™¨
        analyzer_config = get_analyzer_config(self.config_path)
        analyzer_class = AnalyzerMap[analyzer_config['analyzer']]
        self.analyzer = analyzer_class(**analyzer_config['setting'])
        # å†…å­˜ç¼“å­˜
        self.results_cache = {}

        # åˆå§‹åŒ–ç¼“å­˜é…ç½®
        cache_dir = self.config['cache'].get('dir')
        if not os.path.isabs(cache_dir):
            cache_dir = os.path.join(self.config_dir, cache_dir)
        self.cache_dir = Path(cache_dir)
        self.cache_max_age = self.config['cache'].get('max_age')
        self.cleanup_on_start = self.config['cache'].get('cleanup_on_start')

        # åˆ›å»ºç¼“å­˜ç›®å½•
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        print(f"ç¼“å­˜ç›®å½•: {self.cache_dir}")
        print(f"ç¼“å­˜æœ‰æ•ˆæœŸ: {self.cache_max_age / 86400:.1f} å¤©")
        # å¯åŠ¨æ—¶æ‰«æç¼“å­˜ç›®å½•
        self.scan_cache_files()
        # å¦‚æœé…ç½®äº†å¯åŠ¨æ—¶æ¸…ç†ï¼Œæ‰§è¡Œæ¸…ç†
        if self.cleanup_on_start:
            print("å¯åŠ¨æ—¶æ¸…ç†è¿‡æœŸç¼“å­˜...")
            self.clean_cache_files()

        # å‰ç«¯æ ¹ç›®å½•å¯ä»¥æ˜¯ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹äºé…ç½®æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ç›¸å¯¹è·¯å¾„
        frontend_root = self.config['server'].get('frontend_root')
        if not os.path.isabs(frontend_root):
            frontend_root = os.path.join(self.config_dir, frontend_root)
        self.frontend_root = Path(frontend_root)
        print(f"å‰ç«¯æ ¹ç›®å½•: {self.frontend_root}")
        # ç¡®ä¿å‰ç«¯ç›®å½•å­˜åœ¨
        if not os.path.exists(self.frontend_root):
            raise FileNotFoundError(f"å‰ç«¯ç›®å½•ä¸å­˜åœ¨: {self.frontend_root}")

        # æ£€æŸ¥ç¤ºä¾‹æ–‡ä»¶
        sample_file = self.config['server'].get('sample_file')
        if not os.path.isabs(sample_file):
            sample_file = Path(os.path.join(self.config_dir, sample_file))
        self.sample_file = Path(sample_file)
        if not os.path.exists(self.sample_file):
            print(f"è­¦å‘Š, ç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨: {self.sample_file}")
            self.sample_file = None

        # è·å–ä¸Šä¼ ä¿å­˜é…ç½®
        self.save_upload = self.config['server'].get('save_upload')
        # å­˜å‚¨æ–‡ä»¶å“ˆå¸Œæ˜ å°„
        self.file_hash_map = {}
        # å¦‚æœå¯ç”¨ä¸Šä¼ ä¿å­˜åŠŸèƒ½ï¼Œç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨å¹¶æ‰«æå·²æœ‰æ–‡ä»¶
        if self.save_upload:
            upload_dir = self.config['server'].get('upload_dir')
            if not os.path.isabs(upload_dir):
                upload_dir = Path(os.path.join(self.config_dir, upload_dir))
            self.upload_dir = Path(upload_dir)
            self.upload_dir.mkdir(parents=True, exist_ok=True)
            print(f"ä¸Šä¼ ç›®å½•: {self.upload_dir}")
            # å¯åŠ¨æ—¶æ‰«æå·²æœ‰æ–‡ä»¶ï¼Œé‡å»ºå“ˆå¸Œæ˜ å°„
            self.scan_existing_files()
        else:
            self.upload_dir = None
            print("ä¸Šä¼ ä¿å­˜åŠŸèƒ½å·²ç¦ç”¨ï¼Œä¸Šä¼ çš„æ–‡ä»¶å°†ä¸ä¼šè¢«ä¿å­˜")

    def load_config(self, config_path):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

        # è®¾ç½®ç¼“å­˜é»˜è®¤å€¼
        cache_config = config.get('cache', {})
        cache_config.setdefault('dir', './cache')
        cache_config.setdefault('max_age', 2592000)  # 30å¤©
        cache_config.setdefault('cleanup_on_start', False)

        # è®¾ç½®æœåŠ¡å™¨é»˜è®¤å€¼
        server_config = config.get('server', {})
        server_config.setdefault('host', '127.0.0.1')
        server_config.setdefault('port', 8080)
        server_config.setdefault('frontend_root', './frontend')
        server_config.setdefault('sample_file', './sample-msg.json')
        server_config.setdefault('save_upload', False)  # ä¸Šä¼ ä¿å­˜å¼€å…³
        server_config.setdefault('upload_dir', './uploads')
        server_config.setdefault('max_upload_size', 10)
        server_config.setdefault('allowed_extensions', [
                                 '.jpg', '.jpeg', '.png', '.webp'])
        server_config.setdefault('debug', False)  # è°ƒè¯•å¼€å…³

        # è®¾ç½®å‰ç«¯é»˜è®¤å€¼
        frontend_config = config.get('frontend', {})
        frontend_config.setdefault('title', 'å›¾ç‰‡åˆ†æç³»ç»Ÿ')
        frontend_config.setdefault('subtitle', 'åŸºäºAIçš„å›¾ç‰‡åˆ†æä¸æè¿°')
        frontend_config.setdefault('theme', 'light')
        frontend_config.setdefault('show_sample_data', True)

        config['cache'] = cache_config
        config['server'] = server_config
        config['frontend'] = frontend_config

        return config

    def get_file_hash(self, image_data):
        """è®¡ç®—æ–‡ä»¶çš„å“ˆå¸Œå€¼"""
        return hashlib.sha1(image_data).hexdigest()

    def scan_cache_files(self):
        """æ‰«æç¼“å­˜ç›®å½•ä¸­çš„å·²æœ‰ç¼“å­˜æ–‡ä»¶"""
        print(f"æ­£åœ¨æ‰«æç¼“å­˜ç›®å½• ...")
        self.cache_files = {}
        for file_path in self.cache_dir.iterdir():
            if file_path.is_file() and file_path.suffix.lower() == '.json':
                cache_key = file_path.stem  # æ–‡ä»¶åä½œä¸ºç¼“å­˜é”®
                self.cache_files[cache_key] = {
                    'path': str(file_path),
                    'mtime': file_path.stat().st_mtime
                }
                print(f"æ‰¾åˆ°ç¼“å­˜æ–‡ä»¶: {cache_key}")
        print(f"æ‰«æå®Œæˆï¼Œæ‰¾åˆ° {len(self.cache_files)} ä¸ªç¼“å­˜æ–‡ä»¶")

    def scan_existing_files(self):
        """æ‰«æä¸Šä¼ ç›®å½•ä¸­å·²å­˜åœ¨çš„æ–‡ä»¶ï¼Œé‡å»ºæ–‡ä»¶å“ˆå¸Œæ˜ å°„"""
        if not self.save_upload or self.upload_dir is None:
            return

        print(f"æ­£åœ¨æ‰«æä¸Šä¼ ç›®å½• ...")
        # è·å–å…è®¸çš„æ–‡ä»¶æ‰©å±•å
        allowed_extensions = self.config['server']['allowed_extensions']
        # éå†ä¸Šä¼ ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        for file_path in self.upload_dir.iterdir():
            if file_path.is_file():
                # æ£€æŸ¥æ–‡ä»¶æ‰©å±•åæ˜¯å¦åœ¨å…è®¸çš„åˆ—è¡¨ä¸­
                file_ext = file_path.suffix.lower()
                if allowed_extensions and file_ext not in allowed_extensions:
                    print(f"è·³è¿‡éå…è®¸æ‰©å±•åæ–‡ä»¶: {file_path.name}")
                    continue
                # ä»æ–‡ä»¶åä¸­æå–å“ˆå¸Œå€¼ï¼ˆ{hash}{extension}ï¼‰
                file_stem = file_path.stem  # è·å–ä¸å¸¦æ‰©å±•åçš„æ–‡ä»¶å
                # è¯»å–æ–‡ä»¶å†…å®¹è®¡ç®—å“ˆå¸Œå€¼è¿›è¡ŒéªŒè¯
                try:
                    with open(file_path, 'rb') as f:
                        file_data = f.read()
                    actual_hash = self.get_file_hash(file_data)
                    # éªŒè¯æ–‡ä»¶åä¸­çš„å“ˆå¸Œå€¼æ˜¯å¦ä¸å®é™…æ–‡ä»¶å†…å®¹åŒ¹é…
                    if file_stem != actual_hash:
                        print(f"è­¦å‘Š: æ–‡ä»¶ {file_path.name} çš„å“ˆå¸Œå€¼ä¸åŒ¹é…ï¼Œè·³è¿‡")
                        continue
                    # æ·»åŠ åˆ°å“ˆå¸Œæ˜ å°„ä¸­
                    self.file_hash_map[actual_hash] = str(file_path)
                    print(f"å·²æ·»åŠ åˆ°å“ˆå¸Œæ˜ å°„: {actual_hash} -> {file_path}")
                except Exception as e:
                    print(f"å¤„ç†æ–‡ä»¶ {file_path.name} æ—¶å‡ºé”™: {str(e)}")
        print(f"æ‰«æå®Œæˆï¼Œæ‰¾åˆ° {len(self.file_hash_map)} ä¸ªæœ‰æ•ˆæ–‡ä»¶")

    def save_uploaded_file(self, image_data, mime_type, file_hash):
        """ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶ï¼Œå¦‚æœå·²å­˜åœ¨åˆ™ä¸é‡å¤ä¿å­˜"""
        # å¦‚æœä¸Šä¼ ä¿å­˜åŠŸèƒ½ç¦ç”¨ï¼Œç›´æ¥è¿”å›None
        if not self.save_upload:
            return None
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå“ˆå¸Œçš„æ–‡ä»¶
        if file_hash in self.file_hash_map:
            existing_file = self.file_hash_map[file_hash]
            print(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œä½¿ç”¨ç°æœ‰æ–‡ä»¶: {existing_file}")
            return existing_file
        # ç”Ÿæˆæ–‡ä»¶å
        extension = mimetypes.guess_extension(mime_type) or '.jpg'
        filename = f"{file_hash}{extension}"
        filepath = self.upload_dir / filename
        # ä¿å­˜æ–‡ä»¶
        with open(filepath, 'wb') as f:
            f.write(image_data)
        # æ›´æ–°å“ˆå¸Œæ˜ å°„
        self.file_hash_map[file_hash] = str(filepath)
        print(f"æ–‡ä»¶å·²ä¿å­˜: {filepath}")
        return str(filepath)

    def get_cache_file_path(self, cache_key):
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        return self.cache_dir / f"{cache_key}.json"

    def load_from_cache(self, cache_key):
        """ä»ç¼“å­˜æ–‡ä»¶åŠ è½½ç»“æœ"""
        cache_file = self.get_cache_file_path(cache_key)
        if cache_file.exists():
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
                cache_time = cache_data.get('timestamp', 0)
                if time.time() - cache_time < self.cache_max_age:
                    return cache_data
                else:
                    print(f"ç¼“å­˜å·²è¿‡æœŸ: {cache_key}")
                    # è¿‡æœŸæ–‡ä»¶ä¸åˆ é™¤ï¼Œç”±æ¸…ç†ä»»åŠ¡å¤„ç†
                    return None
            except Exception as e:
                print(f"è¯»å–ç¼“å­˜æ–‡ä»¶å¤±è´¥: {cache_key}, é”™è¯¯: {str(e)}")
                return None
        return None

    def save_to_cache(self, cache_key, result):
        """ä¿å­˜ç»“æœåˆ°ç¼“å­˜æ–‡ä»¶"""
        cache_data = {
            'result': result,
            'timestamp': time.time(),
            'cache_key': cache_key
        }
        cache_file = self.get_cache_file_path(cache_key)
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            print(f"ç»“æœå·²ä¿å­˜åˆ°ç¼“å­˜: {cache_file}")
            # æ›´æ–°ç¼“å­˜æ–‡ä»¶æ˜ å°„
            self.cache_files[cache_key] = {
                'path': str(cache_file),
                'mtime': cache_file.stat().st_mtime
            }
        except Exception as e:
            print(f"ä¿å­˜ç¼“å­˜æ–‡ä»¶å¤±è´¥: {str(e)}")

    def analyze_image(self, image_data, mime_type):
        """åˆ†æå›¾ç‰‡å¹¶è¿”å›ç»“æœ"""
        try:
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key = self.get_file_hash(image_data)
            # é¦–å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
            if cache_key in self.results_cache:
                cached_result = self.results_cache[cache_key]
                # æ£€æŸ¥å†…å­˜ç¼“å­˜æ˜¯å¦è¿‡æœŸ
                if time.time() - cached_result['timestamp'] < self.cache_max_age:
                    print(f"ä½¿ç”¨å†…å­˜ç¼“å­˜ç»“æœ: {cache_key}")
                    return {'result': cached_result['result'], 'cache_key': cache_key}
                else:
                    # å†…å­˜ç¼“å­˜è¿‡æœŸï¼Œåˆ é™¤
                    del self.results_cache[cache_key]
            # ç„¶åæ£€æŸ¥ç£ç›˜ç¼“å­˜
            cache_data = self.load_from_cache(cache_key)
            if cache_data:
                print(f"ä½¿ç”¨ç£ç›˜ç¼“å­˜ç»“æœ: {cache_key}")
                # æ›´æ–°åˆ°å†…å­˜ç¼“å­˜
                self.results_cache[cache_key] = cache_data
                return {'result': cache_data['result'], 'cache_key': cache_key}

            # æ‰§è¡Œåˆ†æ
            print("å¼€å§‹åˆ†æå›¾ç‰‡...")
            start_time = time.time()
            result = self.analyzer.chat(image_data, mime_type)
            if self.config['server'].get('debug', False):
                print("[D] image_data:", image_data[:15], " ...")
                print("[D] result:", result)
            elapsed = time.time() - start_time
            print(f"åˆ†æå®Œæˆï¼Œè€—æ—¶: {elapsed:.2f}ç§’")

            # ä¿å­˜åˆ°å†…å­˜ç¼“å­˜
            cache_data = {
                'result': result,
                'timestamp': time.time(),
                'cache_key': cache_key
            }
            self.results_cache[cache_key] = cache_data
            # ä¿å­˜åˆ°ç£ç›˜ç¼“å­˜
            self.save_to_cache(cache_key, result)

            return {'result': result, 'cache_key': cache_key}

        except Exception as e:
            print(f"åˆ†æå¤±è´¥: {str(e)}")
            return {'error': str(e)}

    def clean_cache_files(self):
        """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ–‡ä»¶"""
        print("æ¸…ç†è¿‡æœŸç¼“å­˜æ–‡ä»¶...")
        now = time.time()
        expired_files = []

        for cache_key, cache_info in list(self.cache_files.items()):
            cache_file = Path(cache_info['path'])
            if cache_file.exists():
                # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                file_mtime = cache_file.stat().st_mtime
                if now - file_mtime > self.cache_max_age:
                    try:
                        # è¯»å–æ–‡ä»¶è·å–ç¡®åˆ‡çš„æ—¶é—´æˆ³
                        with open(cache_file, 'r', encoding='utf-8') as f:
                            cache_data = json.load(f)
                        cache_time = cache_data.get('timestamp', file_mtime)

                        if now - cache_time > self.cache_max_age:
                            expired_files.append(cache_file)
                    except:
                        # å¦‚æœè¯»å–å¤±è´¥ï¼Œä½¿ç”¨æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                        if now - file_mtime > self.cache_max_age:
                            expired_files.append(cache_file)

        # åˆ é™¤è¿‡æœŸæ–‡ä»¶
        deleted_count = 0
        for cache_file in expired_files:
            try:
                cache_file.unlink()
                cache_key = cache_file.stem
                if cache_key in self.cache_files:
                    del self.cache_files[cache_key]
                if cache_key in self.results_cache:
                    del self.results_cache[cache_key]
                print(f"åˆ é™¤è¿‡æœŸç¼“å­˜: {cache_file.name}")
                deleted_count += 1
            except Exception as e:
                print(f"åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥: {cache_file}, é”™è¯¯: {str(e)}")
        print(f"æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} ä¸ªè¿‡æœŸç¼“å­˜æ–‡ä»¶")
        return deleted_count

    def clean_low_confidence_uploads(self, confidence_threshold=0.5, dry_run=False):
        """æ¸…ç†ä½ç½®ä¿¡åº¦çš„ä¸Šä¼ æ–‡ä»¶"""
        if not self.save_upload or self.upload_dir is None:
            print("ä¸Šä¼ ä¿å­˜åŠŸèƒ½æœªå¯ç”¨ï¼Œæ— æ³•æ¸…ç†ä¸Šä¼ æ–‡ä»¶")
            return 0
        print(f"æ¸…ç†ç½®ä¿¡åº¦ä½äº {confidence_threshold} çš„ä¸Šä¼ æ–‡ä»¶...")
        if dry_run:
            print("æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ - ä¸ä¼šå®é™…åˆ é™¤æ–‡ä»¶")

        deleted_count = 0
        # è·å–å…è®¸çš„æ–‡ä»¶æ‰©å±•å
        allowed_extensions = self.config['server']['allowed_extensions']
        # éå†ä¸Šä¼ ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        for file_path in self.upload_dir.iterdir():
            if file_path.is_file():
                # æ£€æŸ¥æ–‡ä»¶æ‰©å±•åæ˜¯å¦åœ¨å…è®¸çš„åˆ—è¡¨ä¸­
                file_ext = file_path.suffix.lower()
                if allowed_extensions and file_ext not in allowed_extensions:
                    continue
                # ä»æ–‡ä»¶åä¸­æå–å“ˆå¸Œå€¼
                file_stem = file_path.stem
                # æŸ¥æ‰¾å¯¹åº”çš„ç¼“å­˜æ–‡ä»¶
                cache_file = self.get_cache_file_path(file_stem)
                if cache_file.exists():
                    try:
                        with open(cache_file, 'r', encoding='utf-8') as f:
                            cache_data = json.load(f)
                        # è·å–ç½®ä¿¡åº¦
                        result = cache_data.get('result', {})
                        confidence = result.get('confidence', 1.0)
                        if confidence < confidence_threshold:
                            print(
                                f"æ–‡ä»¶ {file_path.name} ç½®ä¿¡åº¦ {confidence:.2f} ä½äºé˜ˆå€¼ {confidence_threshold}")
                            if not dry_run:
                                # åˆ é™¤ä¸Šä¼ æ–‡ä»¶
                                file_path.unlink()
                                print(f"å·²åˆ é™¤ä¸Šä¼ æ–‡ä»¶: {file_path.name}")
                                # ä»å“ˆå¸Œæ˜ å°„ä¸­ç§»é™¤
                                if file_stem in self.file_hash_map:
                                    del self.file_hash_map[file_stem]
                                # åˆ é™¤ç¼“å­˜æ–‡ä»¶
                                cache_file.unlink()
                                print(f"å·²åˆ é™¤ç¼“å­˜æ–‡ä»¶: {cache_file.name}")
                                # ä»å†…å­˜ç¼“å­˜ä¸­ç§»é™¤
                                if file_stem in self.results_cache:
                                    del self.results_cache[file_stem]
                                # ä»ç¼“å­˜æ–‡ä»¶æ˜ å°„ä¸­ç§»é™¤
                                if file_stem in self.cache_files:
                                    del self.cache_files[file_stem]
                            deleted_count += 1
                    except Exception as e:
                        print(f"å¤„ç†æ–‡ä»¶ {file_path.name} æ—¶å‡ºé”™: {str(e)}")
        print(f"æ‰¾åˆ° {deleted_count} ä¸ªä½ç½®ä¿¡åº¦æ–‡ä»¶" + (" (æ¨¡æ‹Ÿè¿è¡Œ)" if dry_run else ""))
        return deleted_count


# aimglyze-light-16x16.ico
DEFAULT_FAVICON = base64.b64decode(
    """AAABAAEAEBAAAAEACABoBQAAFgAAACgAAAAQAAAAIAAAAAEACAAAAAAAAAEAABMLAAATCwAAAAEA
AAABAADLhD0Ay4U+ANaALwDdjDsA0YtBANGKQQDKgzwAz4g/AP+mRQD/uFgA8ncfABIAAACcSxMA
gDoJAKFNFACaSRMA/8k/APdvCAB5NggAfDgHANOQSADVkEUA1pFFANeVSwDXlUoA15RJANeUSgDX
lEoA1pRKAMmEPgDRiUAA1Y5EANqZUQDbnFUA3J9ZANqWSwDbmU8A25pRANuZTgDalUgA2ZNHANWP
RQDPiUEAyoA4AM6FPADVjEAAz4Y8AL90MADGeTEAzX81AMJ3MQC/cCsAw3MsAMh3LgDAcSsAvGom
AL5tKADEcSgAvGomALllIgC+bCQAxXImALdkIgC2YiAAv2skAMFuIwCyXh8AtF4eAL9rIwC0YB4A
r1scALFbHAC9ZyEArFYYAKtXGgCwWxsAt18cAKlTFgCnUxcAq1YYALRbGgCnUhYAo1AVAKJQFgCv
VxgAlUwWAKNNEgCnURUAsVcYAGwxCAB4NwkAlEYSAKROFACrUxYAsFcYALNZGQC0WhkAslgZAK9W
FwCqUxYAnUwTAIc/DABxMgQAhT4OAJBEEQCQRRIAkUYSAI9FEQCORBEAjEMQAIA8DgDfpV8A8b5v
AOu/fwD11Z0A57p+ANqocwDZqXYA2qVpANyaTgDZkkYAzItHAN+rZgDzv2oA7sJ8AP3clgD+3psA
5bd6ANeXSwDYnVYA2qFXANeUSQDShTkAxodFAMWLSQDOmVcA2KVjAO/EfAD1zYQA7caGAN2saQDj
s3MA4rR6ANuocADMfTMAtnc1AKtxLwC9kF8A58mXAOrUnwD51pQA9taZAN/ElgDbwZYA6cqQAO3J
lADOhDcAtHErAJleHwC5k2cAzdq0AJDY2ADu2pgA2bJyANywcADktm4A161vAMyrfwDMhz0AwHMo
AKlmIwCwhlkA5+PBALbXuADSx5IA1p9SAO3QowDXrHAAv7hxAL2bXQDDhkUAzoQxAMd5KAC9hEgA
u8iTAHykRgCbn1sAvX4+AM+rfgC/kl4AkI1TAKqAPwC7fkEAzH4uAM+EMQDGhkEAip1YAE6CFwB8
hD4AtoZTAL6UaADEmGUAtn05AMSPSwC2fUUAxXInANKKNgDKhjsArMGOAILJggCLsHgAtZhkAL2P
VwDLnV8A1atsAMWfaQCmZzMAvWQfAM6AMADNiDUAu5NhALOUZQCofUwAl2EnAJ9qMACldUAAnXA9
AK6DSwCuai0AuF4bAMFpIQDLeykAyXwoAM2CKQDKgCgAxHwoALt4LACzcikAol8YAHtCEQCKVyYA
uF0bAL9nIADHdScAyXksAMt7KwDOgSsAy3wqAMZ1JwC1YBwAj0UPAP///wAAAAAAAAAAAAAAAAAA
AAAADg8QZ2hpamlra2xtbhESEwxbXF1eX2BQUGFiY2RlZg0KV1jx8vP09fb3+Pn6WVoLU1Tl5ufo
6err7O3u7/BVVk9Q2drb3N3e3+Dh4uPkUVJLTM3Oz9DR0tPU1dbX2E1OR0jBwsPExcbHyMnKy8xJ
SkNEtba3uLm6u7y9vr/ARUY/QKmqq6ytrq+wsbKztEFCOzydnp+goaKjpKWmp6g9Pjc4kZKTlJWW
l5iZmpucOTozNIWGh4iJiouMjY6PkDU2LzB5ent8fX5/gIGCg4QxMggrLG9wcXJzdHV2d3gtLgkG
HR4fICEiIyQlJicoKSoHAAECFBUWFhcYGRobHAMEBeAHAACAAQAAgAEAAAAAAAAAAAAAAAAAAAAA
AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAQAAgAEAAOAHAAA="""
)


class RequestHandler(BaseHTTPRequestHandler):
    """HTTPè¯·æ±‚å¤„ç†å™¨"""

    def __init__(self, *args, **kwargs):
        self.server_instance = kwargs.pop('server_instance')
        super().__init__(*args, **kwargs)

    def do_GET(self):
        """å¤„ç†GETè¯·æ±‚"""
        parsed_path = urlparse(self.path)
        path = parsed_path.path
        # APIè·¯ç”±å¤„ç†
        if path == '/api/config':
            self.send_config()
        elif path == '/api/sample':
            self.send_sample_data()
        elif path == '/api/health':
            self.send_health_check()
        elif path.startswith('/api/results/'):
            self.get_cached_result(path)
        else:
            if path == '/favicon.ico':
                self.send_favicon()
            else:
                # å‰ç«¯æ–‡ä»¶æœåŠ¡
                self.serve_frontend_file(path)

    def do_POST(self):
        """å¤„ç†POSTè¯·æ±‚"""
        if self.path == '/api/analyze':
            self.handle_upload()
        else:
            self.send_error(404, "Not Found")

    def send_favicon(self):
        """å‘é€favicon.icoæ–‡ä»¶"""
        try:
            # å‰ç«¯ç›®å½•ä¸­æ˜¯å¦å­˜åœ¨ favicon.ico
            favicon_path = Path(os.path.join(
                self.server_instance.frontend_root, 'favicon.ico'))
            if favicon_path.exists():
                with open(favicon_path, 'rb') as f:
                    favicon_data = f.read()
            else:
                # ä½¿ç”¨é»˜è®¤çš„favicon.ico
                favicon_data = DEFAULT_FAVICON
            self.send_response(200)
            self.send_header('Content-Type', 'image/x-icon')
            self.send_header('Content-Length', str(len(favicon_data)))
            self.send_header('Cache-Control', 'public, max-age=86400')
            self.send_header('Access-Control-Allow-Origin', '*')
            self.end_headers()
            self.wfile.write(favicon_data)
        except Exception as e:
            self.send_error(500,  str(e))

    def serve_frontend_file(self, path):
        """æä¾›å‰ç«¯é™æ€æ–‡ä»¶"""
        try:
            # å°†URLè·¯å¾„è½¬æ¢ä¸ºæ–‡ä»¶ç³»ç»Ÿè·¯å¾„
            if path == '/':
                filepath = 'index.html'
            else:
                # ç§»é™¤å¼€å¤´çš„æ–œæ 
                filepath = path[1:] if path.startswith('/') else path
            # æ„å»ºå®Œæ•´è·¯å¾„
            full_path = os.path.join(
                self.server_instance.frontend_root, filepath)
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•index.htmlï¼ˆç”¨äºSPAè·¯ç”±ï¼‰
            # if not os.path.exists(full_path):
            #    full_path = os.path.join(
            #        self.server_instance.frontend_root, 'index.html')
            if not os.path.exists(full_path):
                self.send_error(404, f"File not found: {path}")
                return

            with open(full_path, 'rb') as f:
                content = f.read()

            # çŒœæµ‹å†…å®¹ç±»å‹
            content_type = self.guess_content_type(full_path)

            self.send_response(200)
            self.send_header('Content-Type', content_type)
            self.send_header('Content-Length', str(len(content)))
            self.send_header('Access-Control-Allow-Origin', '*')
            self.end_headers()
            self.wfile.write(content)

        except Exception as e:
            self.send_error(500, str(e))

    def guess_content_type(self, filepath):
        """çŒœæµ‹æ–‡ä»¶ç±»å‹"""
        mime_type, _ = mimetypes.guess_type(filepath)
        return mime_type or 'application/octet-stream'

    def send_config(self):
        """å‘é€é…ç½®ä¿¡æ¯"""
        config = self.server_instance.config
        response = {
            'frontend': config['frontend'],
            'allowed_extensions': config['server']['allowed_extensions'],
            'max_upload_size': config['server']['max_upload_size'],
            'save_upload': config['server']['save_upload'],  # ä¸Šä¼ ä¿å­˜å¼€å…³çŠ¶æ€
            'cache_max_age': config['cache']['max_age']
        }
        self.send_json(response)

    def send_sample_data(self):
        """å‘é€ç¤ºä¾‹æ•°æ®"""
        try:
            sample_file = self.server_instance.sample_file
            if sample_file is None:
                self.send_error(404, "Sample data file not found")
                return
            with open(sample_file, 'r', encoding='utf-8') as f:
                sample_data = json.load(f)
            # æ·»åŠ ç¤ºä¾‹æ ‡è®°
            sample_data['is_sample'] = True
            sample_data['timestamp'] = Path(sample_file).stat().st_mtime
            self.send_json(sample_data)
        except Exception as e:
            self.send_error(500, f"Failed to load sample data: {str(e)}")

    def send_health_check(self):
        """å‘é€å¥åº·æ£€æŸ¥å“åº”"""
        response = {
            'status': 'ok',
            'timestamp': time.time(),
            'cache_stats': {
                'memory_cache_count': len(self.server_instance.results_cache),
                'disk_cache_count': len(self.server_instance.cache_files),
                'upload_files_count': len(self.server_instance.file_hash_map) if self.server_instance.save_upload else 0
            }
        }
        self.send_json(response)

    def get_cached_result(self, path):
        """è·å–ç¼“å­˜çš„åˆ†æç»“æœ"""
        try:
            cache_key = path.split('/')[-1]
            if cache_key in self.server_instance.results_cache:
                data = self.server_instance.results_cache[cache_key]
                self.send_json(data)
            else:
                # å°è¯•ä»ç£ç›˜åŠ è½½
                cache_data = self.server_instance.load_from_cache(cache_key)
                if cache_data:
                    # æ›´æ–°åˆ°å†…å­˜ç¼“å­˜
                    self.server_instance.results_cache[cache_key] = cache_data
                    self.send_json(cache_data)
                else:
                    self.send_error(404, "Result not found")
        except Exception as e:
            self.send_error(500, str(e))

    def handle_upload(self):
        """å¤„ç†æ–‡ä»¶ä¸Šä¼ å’Œåˆ†æ"""
        try:
            # æ£€æŸ¥å†…å®¹ç±»å‹
            content_type = self.headers.get('Content-Type', '')
            if 'multipart/form-data' not in content_type:
                self.send_error(400, "Expected multipart/form-data")
                return
            # è¯»å–è¯·æ±‚ä½“
            content_length = int(self.headers.get('Content-Length', 0))
            if content_length == 0:
                self.send_error(400, "Empty request body")
                return

            # è§£æmultipart/form-data
            post_data = self.rfile.read(content_length)
            # ç®€åŒ–çš„multipartè§£æï¼ˆå®é™…åº”ç”¨ä¸­å»ºè®®ä½¿ç”¨email.parseræˆ–ç¬¬ä¸‰æ–¹åº“ï¼‰
            boundary = content_type.split('boundary=')[1].encode()
            parts = post_data.split(b'--' + boundary)

            image_data = None
            mime_type = None
            for part in parts:
                if b'Content-Disposition: form-data; name="file"' in part:
                    # æå–æ–‡ä»¶æ•°æ®
                    header_end = part.find(b'\r\n\r\n')
                    if header_end != -1:
                        image_data = part[header_end + 4:]
                        # å»æ‰ç»“å°¾çš„\r\n
                        if image_data.endswith(b'\r\n'):
                            image_data = image_data[:-2]
                        # æå–MIMEç±»å‹
                        headers = part[:header_end].decode(
                            'utf-8', errors='ignore')
                        for line in headers.split('\r\n'):
                            if line.lower().startswith('content-type:'):
                                mime_type = line.split(': ')[1].strip()
                                break
                        break

            if not image_data or not mime_type:
                self.send_error(400, "No file uploaded")
                return

            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            max_size = self.server_instance.config['server']['max_upload_size'] * 1024 * 1024
            if len(image_data) > max_size:
                self.send_error(
                    413, f"File too large (max {max_size/1024/1024}MB)")
                return

            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
            file_hash = self.server_instance.get_file_hash(image_data)
            # ä¿å­˜æ–‡ä»¶ï¼ˆå¦‚æœå¯ç”¨ä¸Šä¼ åŠŸèƒ½ï¼‰
            filepath = None
            if self.server_instance.save_upload:
                filepath = self.server_instance.save_uploaded_file(
                    image_data, mime_type, file_hash)

            # åˆ†æå›¾ç‰‡
            result = self.server_instance.analyze_image(image_data, mime_type)
            # åœ¨ç»“æœä¸­æ·»åŠ æ–‡ä»¶ä¿¡æ¯
            if 'result' in result:
                result['file_info'] = {
                    'hash': file_hash,
                    'path': os.path.basename(filepath) if filepath else None,
                    'size': len(image_data),
                    'mime_type': mime_type,
                    'saved': filepath is not None  # æ ‡è®°æ–‡ä»¶æ˜¯å¦è¢«ä¿å­˜
                }

            # è¿”å›ç»“æœ
            self.send_json(result)

        except Exception as e:
            print(f"ä¸Šä¼ å¤„ç†å¤±è´¥: {str(e)}")
            self.send_error(500, str(e))

    def send_json(self, data):
        """å‘é€JSONå“åº”"""
        response = json.dumps(data, ensure_ascii=False).encode('utf-8')

        self.send_response(200)
        self.send_header('Content-Type', 'application/json; charset=utf-8')
        self.send_header('Content-Length', str(len(response)))
        self.send_header('Access-Control-Allow-Origin', '*')
        self.end_headers()
        self.wfile.write(response)

    def send_error(self, code, message):
        """å‘é€é”™è¯¯å“åº”"""
        self.send_response(code)
        self.send_header('Content-Type', 'application/json')
        self.end_headers()

        error_data = {
            'error': True,
            'code': code,
            'message': message
        }

        self.wfile.write(json.dumps(error_data).encode())

    def log_message(self, format, *args):
        """è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼"""
        # æ£€æŸ¥æ˜¯å¦ä¸ºå¥åº·æ£€æŸ¥è¯·æ±‚
        parsed_path = urlparse(self.path)
        if parsed_path.path == '/api/health':
            # åªæœ‰åœ¨è°ƒè¯•æ¨¡å¼ä¸‹æ‰æ‰“å°å¥åº·æ£€æŸ¥æ—¥å¿—
            if self.server_instance.config['server'].get('debug', False):
                print(f"[{self.log_date_time_string()}] {format % args}")
        else:
            # å…¶ä»–è¯·æ±‚æ­£å¸¸æ‰“å°æ—¥å¿—
            print(f"[{self.log_date_time_string()}] {format % args}")


def run_server(config_path):
    """å¯åŠ¨æœåŠ¡å™¨"""
    # debug ç¼–ç æ£€æµ‹
    print("Locale preferred encoding:", locale.getpreferredencoding())
    print("sys default encoding:", sys.getdefaultencoding())

    try:
        # åˆ›å»ºæœåŠ¡å™¨å®ä¾‹
        server = AnalysisServer(config_path)
        server_config = server.config['server']
        # åˆ›å»ºHTTPæœåŠ¡å™¨
        handler_class = lambda *args, **kwargs: RequestHandler(
            *args, **kwargs, server_instance=server)
        httpd = HTTPServer(
            (server_config['host'], server_config['port']), handler_class)
        print(
            f"\nğŸŒ æœåŠ¡å™¨å¯åŠ¨åœ¨ http://{server_config['host']}:{server_config['port']}")
        print("âŒ¨  æŒ‰ Ctrl+C åœæ­¢æœåŠ¡å™¨")
        try:
            httpd.serve_forever()
        except KeyboardInterrupt:
            print("\næœåŠ¡å™¨æ­£åœ¨åœæ­¢...")
            httpd.server_close()
            print("æœåŠ¡å™¨å·²åœæ­¢")
            sys.exit(0)
    except Exception as e:
        import traceback
        print(f"å¯åŠ¨æœåŠ¡å™¨å¤±è´¥: {str(e)}")
        traceback.print_exc()
        sys.exit(1)


def cleanup_cache(config_path):
    """æ¸…ç†è¿‡æœŸç¼“å­˜"""
    try:
        # åˆ›å»ºæœåŠ¡å™¨å®ä¾‹ä»¥è®¿é—®é…ç½®
        server = AnalysisServer(config_path)
        # æ¸…ç†ç¼“å­˜æ–‡ä»¶
        deleted_count = server.clean_cache_files()
        return deleted_count
    except Exception as e:
        print(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {str(e)}")
        return 0


def cleanup_low_confidence_uploads(config_path, confidence_threshold=0.5, dry_run=False):
    """æ¸…ç†ä½ç½®ä¿¡åº¦çš„ä¸Šä¼ æ–‡ä»¶"""
    try:
        # åˆ›å»ºæœåŠ¡å™¨å®ä¾‹ä»¥è®¿é—®é…ç½®
        server = AnalysisServer(config_path)
        # æ¸…ç†ä½ç½®ä¿¡åº¦æ–‡ä»¶
        deleted_count = server.clean_low_confidence_uploads(
            confidence_threshold, dry_run)
        return deleted_count
    except Exception as e:
        print(f"æ¸…ç†ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {str(e)}")
        return 0


if __name__ == "__main__":
    run_server('./aimglyze/apps/App-DescTags/config.yaml')
